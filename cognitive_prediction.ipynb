{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#load in data\n",
    "#fc and sc are upper triangular vectors for each subject; rows are subjects, columns are pairwise connectivity\n",
    "fc = pd.read_csv('fc.csv', header=None).values\n",
    "sc = pd.read_csv('sc.csv', header=None).values\n",
    "\n",
    "#generate hybrid connectivity\n",
    "hc=np.concatenate((sc, fc), axis=1)\n",
    "\n",
    "#select data you want to put into the model\n",
    "data = hc\n",
    "\n",
    "#load in cognition data; rows are subjects\n",
    "cognition = pd.read_csv('cognition.csv', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with NaN for cognition\n",
    "data_clean=data[~np.isnan(cognition).any(axis=1)]\n",
    "cog_clean=cognition[~np.isnan(cognition).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Model Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the number of permutations and cross-validation loops\n",
    "permutations = 100\n",
    "cv_loops = 10\n",
    "\n",
    "#set the hyperparameter gridsearch space\n",
    "alphas=[x*10+10 for x in range(10)\n",
    "\n",
    "#set the model you want to use and the parameter grid to use\n",
    "regr = Ridge(max_iter = 1000000, normalize=True)\n",
    "paramGrid = {'alpha': alphas}\n",
    "\n",
    "#set specific cognition metric you want to predict\n",
    "cog_metric = cog_clean[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create variables to store results\n",
    "r2 = np.zeros(permutations)\n",
    "var = np.zeros(permutations)\n",
    "correlation = np.zeros(permutations)\n",
    "opt_alpha = np.zeros(permutations)\n",
    "tuned_alphas = np.zeros([permutations,cv_loops])\n",
    "predictions = np.zeros([permutations,int(np.ceil(data_clean.shape[0]*0.2))])\n",
    "cog_test = np.zeros([permutations,int(np.ceil(data_clean.shape[0]*0.2))])\n",
    "feat_imp = np.zeros([permutations,data_clean.shape[1]])\n",
    "\n",
    "#iterate through the permutations\n",
    "for perm in range (permutations):\n",
    "    \n",
    "    print(\"Permutation %d\" % perm)\n",
    "    print(time.localtime(time.time()))\n",
    "    \n",
    "    #split data into training and testing set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_clean, cog_metric, test_size=0.2, shuffle=True, random_state=perm)\n",
    "    \n",
    "    #create variables to store scores and params from cross-validation loop\n",
    "    nested_scores = []\n",
    "    best_params = []\n",
    "\n",
    "    #iterate through cross-validation loops\n",
    "    for i in range(cv_loops):\n",
    "        \n",
    "        \n",
    "        #set parameters for inner and outer loops for CV\n",
    "        inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "        outer_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "        \n",
    "        #define regressor with grid-search CV for inner loop\n",
    "        gridSearch = GridSearchCV(estimator=regr, param_grid=paramGrid, n_jobs=-1, verbose=0, cv=inner_cv)\n",
    "        \n",
    "        #fit regression model using inner cross-validation \n",
    "        gridSearch.fit(x_train, y_train)\n",
    "\n",
    "        #save parameters corresponding to the best score\n",
    "        best_params.append(list(gridSearch.best_params_.values()))\n",
    "\n",
    "        #evaluate model trained on inner loop for CV using outer loop\n",
    "        nested_score = cross_val_score(gridSearch, X=x_train, y=y_train, cv=outer_cv, \n",
    "                                       scoring='r2', verbose=0)\n",
    "        \n",
    "        #save r2 scores from outer loop \n",
    "        nested_scores.append(np.median(nested_score))\n",
    "\n",
    "    # save best params\n",
    "    with open('best_params.txt', 'w') as file:\n",
    "        for listitem in best_params:\n",
    "            file.write('{}\\n'.format(listitem))    \n",
    "\n",
    "    # extract best params\n",
    "    cv_alphas = []\n",
    "    with open('best_params.txt', 'r') as file:\n",
    "        for row in file:\n",
    "            row = row.replace('[', '')\n",
    "            row = row.replace(']', '')\n",
    "            pair = row.split(',')\n",
    "            cv_alphas.append(float(pair[0]))\n",
    "    \n",
    "    #save tuned hyperparameters\n",
    "    tuned_alphas[perm,:] = np.asarray(cv_alphas)\n",
    "\n",
    "    #choose optimised hyperparameter based on median of tuned hyperparameters\n",
    "    opt_alpha[perm] = np.median(cv_alphas)\n",
    "    \n",
    "    #fit model with optimised hyperparameters on entire training set\n",
    "    model = Ridge(alpha=optimized_alpha, max_iter=1000000, normalize=True)\n",
    "    model.fit(x_train, y_train);\n",
    "    \n",
    "    #evaluate test r2    \n",
    "    r2[perm] = model.score(x_test,y_test)\n",
    "    \n",
    "    #store test y values\n",
    "    cog_test[perm,:] = y_test\n",
    "\n",
    "    #store model predictions\n",
    "    predictions[perm,:] = model.predict(x_test)\n",
    "    \n",
    "    #compute explained variance\n",
    "    var[perm]=explained_variance_score(cog_test[perm,:], predictions[perm,:])\n",
    "\n",
    "    #compute Pearson correlation between true and predicted y \n",
    "    correlation[perm] = np.corrcoef(cog_test[perm,:], predictions[perm,:])[1,0]\n",
    "\n",
    "    #store feature importance from model\n",
    "    feat_imp[perm,:] = model.coef_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results at the end of each permutation\n",
    "np.savetxt('r2.txt', r2, delimiter=',')\n",
    "np.savetxt('var.txt', var, delimiter=',')\n",
    "np.savetxt('correlation.txt', correlation, delimiter=',')\n",
    "np.savetxt('opt_alpha.txt', opt_alpha, delimiter=',')\n",
    "np.savetxt('predictions.txt', predictions, delimiter=',')\n",
    "np.savetxt('cog_test.txt', cog_test, delimiter=',')\n",
    "np.savetxt('feat_imp.txt', feat_imp, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
